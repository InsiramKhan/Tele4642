<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Machine Learning – IntelliHome SDN</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <header class="global-header">
  <div class="left-brand">
    <a href="index.html" class="logo-nav">Intelli<span class="highlight">Home</span></a>
  </div>
  <nav class="main-nav">
    <a href="overview.html">Overview</a>
    <a href="architecture.html">Architecture</a>
    <a href="ml.html">ML</a>
    <a href="pagerank.html">PageRank</a>
    <a href="demo.html">Demo</a>
    <a href="results_eval.html">Results</a>
  </nav>
</header>

  <main class="content-wrapper">
    <section id="ml">
        <h1>Machine Learning – Flow Anomaly Detection</h1>
        <p>
          <strong>Runtime Inference:</strong> <code>model_engine.py</code> &nbsp;|&nbsp;
          <strong>Used by:</strong> <code>ryu_project.py</code> (after MUD pre-check) &nbsp;|&nbsp;
          <strong>Retraining:</strong> <code>retrain_from_logs.py</code>
        </p>

        <!-- ================= Overview ================ -->
        <h2>1) Overview</h2>
        <p>
          The ML engine classifies flows as <em>benign</em> or <em>malicious</em> in real time. It is invoked only for flows that are <em>not</em> outright denied by the MUD baseline.
          Decisions are fused with MUD verdicts and a PageRank-based trust score (see Architecture) before programming OpenFlow rules.
        </p>
        <ul>
          <li><strong>Model family:</strong> Random Forest (sklearn), persisted as <code>rf_model.pkl</code></li>
          <li><strong>Latency budget:</strong> &lt; 3&nbsp;ms per inference (typical dev laptop)</li>
          <li><strong>Outputs:</strong> <code>label</code> ∈ {<code>benign</code>, <code>malicious</code>} + <code>score</code> ∈ [0,1] (malicious probability)</li>
          <li><strong>Serving path:</strong> <code>ryu_project.py</code> → feature extraction → <code>model_engine.classify_flow(features)</code></li>
        </ul>

        <!-- ================= Data & Labels ================ -->
        <h2>2) Data & Labeling</h2>
        <p>Training data is produced by the controller logs and test harness:</p>
        <ul>
          <li><strong>Benign:</strong> normal IoT behaviour (DNS/NTP/HTTPS to vendor endpoints, LAN chatter).</li>
          <li><strong>Malicious:</strong> scripted scans, port sweeps, UDP/ICMP floods, policy-drift destinations, blocklisted IPs.</li>
          <li><strong>Ground truth:</strong> generated by the traffic harness and controller decisions; reviewed to reduce label noise.</li>
        </ul>

        <h3>2.1 Log schema (per row)</h3>
        <pre><code># flows_log.csv (union of multiple files allowed)
      timestamp, device_id, src_ip, dst_ip, proto, src_port, dst_port, bytes, pkts, duration,
      inter_arrival_mean, inter_arrival_std, conn_attempts_window, port_rarity,
      mud_verdict, ml_label, ml_score, trust_score, final_decision, ground_truth_label
        </code></pre>

        <!-- ================= Features ================ -->
        <h2>3) Features</h2>
        <p>Computed in <code>ryu_project.py</code> before inference:</p>
        <ul>
          <li><strong>Identity / Header:</strong> <code>proto</code> (one-hot/ordinal), <code>src_port</code>, <code>dst_port</code> (binned/rare), <code>device_id</code> (optional embedding/one-hot).</li>
          <li><strong>Size / Rate:</strong> <code>pkt_len</code>, <code>bytes</code>, <code>pkts</code>, <code>duration</code>, <code>bpp</code>=bytes/pkt, <code>pps</code>=pkts/s.</li>
          <li><strong>Temporal:</strong> <code>inter_arrival_mean</code>, <code>inter_arrival_std</code>, <code>burstiness</code>=CV.</li>
          <li><strong>Heuristics:</strong> <code>port_rarity</code> (device/profile-aware), <code>conn_attempts_window</code> (N attempts / Δt).</li>
        </ul>
        <p><em>Preprocessing:</em> type casts, missing-value imputation, scaling where relevant; categorical encodings kept in the model pipeline.</p>

        <!-- ================= Inference API ================ -->
        <h2>4) Online Inference API (<code>model_engine.py</code>)</h2>
        <pre><code>from model_engine import classify_flow

      features = {
        "proto": 6, "src_port": 51524, "dst_port": 443,
        "pkt_len": 1180, "bytes": 9216, "pkts": 8, "duration": 1.2,
        "bpp": 1152.0, "pps": 6.7,
        "inter_arrival_mean": 0.18, "inter_arrival_std": 0.05,
        "port_rarity": 0.02, "conn_attempts_window": 1
      }

      label, score = classify_flow(features)  # e.g., ("benign", 0.08)
        </code></pre>

        <h3>4.1 Controller call site (<code>ryu_project.py</code>, conceptual)</h3>
        <pre><code>if mud_verdict == "DENY":
          decision = "DROP"
      else:
          label, score = classify_flow(features)
          # Fuse with trust score and MUD result
          decision = fuse(mud_verdict, label, score, trust_score)
          program_switch(decision, flow_spec)
        </code></pre>

        <!-- ================= Retraining Pipeline ================ -->
        <h2>5) Training & Retraining (<code>retrain_from_logs.py</code>)</h2>
        <p>
          The model can be retrained from accumulated CSV logs (single file or glob). The script handles
          loading, feature engineering, train/val/test split, class imbalance, cross-validation, and persistence.
        </p>

        <h3>5.1 Usage</h3>
        <pre><code># Train from multiple logs and export model + report
      python retrain_from_logs.py
        </code></pre>

        <h3>5.2 What it does</h3>
        <ul>
          <li>Merges CSV logs; filters rows with valid <code>ground_truth_label</code> ∈ {benign, malicious}.</li>
          <li>Applies the same feature engineering as runtime (kept inside the sklearn pipeline).</li>
          <li>Splits data (70/15/15) stratified by label and optionally by <code>device_id</code> to reduce leakage.</li>
          <li>Handles class imbalance via <code>class_weight='balanced'</code> (or sampling).</li>
          <li>Tunes key RF hyperparameters (e.g., <code>n_estimators</code>, <code>max_depth</code>) via cross-validation.</li>
          <li>Outputs: <code>rf_model.pkl</code> (joblib), evaluation JSON, and visuals (confusion matrix, ROC if enabled).</li>
        </ul>

        <h3>5.3 Hot-swap in production</h3>
        <pre><code># point the runtime to the new model (no controller restart if you reload safely)
      export ML_MODEL_PATH=models/rf_model.pkl
      # or set in config JSON and trigger a reload endpoint (if exposed)
        </code></pre>

        <!-- ================= Evaluation & Thresholds ================ -->
        <h2>6) Evaluation & Thresholds</h2>
        <ul>
          <li><strong>Metrics:</strong> Accuracy, Precision, Recall, F1, ROC-AUC; report both macro and weighted averages.</li>
          <li><strong>Confusion matrix:</strong> saved to <code>artifacts/confusion_matrix.png</code>.</li>
          <li><strong>Operating point:</strong> default malicious threshold τ=0.7 (tune per risk appetite).</li>
        </ul>
        <pre><code>{
        "accuracy": 0.964,
        "precision": {"benign": 0.97, "malicious": 0.95},
        "recall":    {"benign": 0.96, "malicious": 0.97},
        "f1":        {"benign": 0.96, "malicious": 0.96},
        "auc": 0.987,
        "threshold": 0.70
      }
        </code></pre>

        <!-- ================= Drift & Retrain Policy ================ -->
        <h2>7) Drift Detection & Retrain Policy</h2>
        <ul>
          <li><strong>Data drift signals:</strong> rise in OOD (out-of-distribution) features, increase in quarantine rate, shift in port distributions.</li>
          <li><strong>Label drift signals:</strong> drop in precision/recall on a rolling validation set.</li>
          <li><strong>Policy:</strong> if FP or FN exceed 5% over a 7-day window, trigger <code>retrain_from_logs.py</code> with the latest logs.</li>
        </ul>

        <!-- ================= Fusion with MUD & Trust ================ -->
        <h2>8) Decision Fusion (MUD ∧ ML ∧ Trust)</h2>
        <pre><code>// conceptual
      if MUD == "DENY":
        decision = DROP
      elif ML_score >= 0.9:
        decision = DROP
      elif ML_score >= 0.7 and Trust < 0.2:
        decision = QUARANTINE
      elif MUD == "ALLOW" and ML_label == "benign" and Trust > 0.4:
        decision = ALLOW
      else:
        decision = RATE_LIMIT
        </code></pre>

        <!-- ================= Reproducibility & Registry ================ -->
        <h2>9) Reproducibility</h2>
        <ul>
          <li>Model artifacts stored under <code>models/</code> with semantic version (e.g., <code>rf_model_v1.2.0.pkl</code>).</li>
          <li>Each version accompanied by <code>artifacts/metrics_report.json</code>, confusion matrix, and training args JSON.</li>
          <li>Runtime config includes the active model path and threshold τ; exposed via <code>/api/metrics</code>.</li>
        </ul>

        <!-- ================= Performance & Safety ================ -->
        <h2>10) Performance & Safety</h2>
        <ul>
          <li>Inference on a background worker to avoid blocking the controller’s I/O loop if needed.</li>
          <li>Graceful fallback: if model fails to load → default to MUD allowlist + rate-limit + alert.</li>
          <li>Input validation on features; clamp outliers; enforce schema to avoid poisoning.</li>
        </ul>

        <!-- ================= Quick Commands (for Demo) ================ -->
        <h2>11) Quick Commands</h2>
        <pre><code># 1) Retrain
                      python retrain_from_logs.py 
  # 2) Run controller (uses new model if configured)
                    ryu-manager ryu_project.py --observe-links

  # 3) Generate mixed traffic in Mininet topology, then inspect UI pages:
  #    - Demo: live events
  #    - Results & Evaluation: metrics, confusion matrix, FP/FN trend
        </code></pre>

        <!-- ================= Cross-Page Links ================ -->
        <h2>12) See Also</h2>
        <ul>
          <li><a href="./architecture.html">System Architecture</a></li>
          <li><a href="./pagerank.html">Flow Scoring (PageRank)</a></li>
          <li><a href="./results_eval.html">Results &amp; Evaluation</a></li>
        </ul>
      </section>


  </main>

  <footer>
    <div class="footer-left">IntelliHome SDN – TELE4642 UNSW</div>
    <div class="footer-right">
      <a href="#">Privacy</a>
      <a href="#">Terms</a>
    </div>
  </footer>
</body>
</html>

